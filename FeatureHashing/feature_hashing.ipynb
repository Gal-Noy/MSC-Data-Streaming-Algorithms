{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, roc_auc_score, confusion_matrix\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from datasets import load_dataset\n",
    "from mfh.multi_feature_hashing import MultiFeatureHasher, dense_X, apply_mfh\n",
    "from models import train_and_evaluate_model\n",
    "from concurrency import parallel_map, parallel_map_2d\n",
    "\n",
    "NUM_HASHES = 3\n",
    "DATASET_NAME = 'news_category'\n",
    "K_VALS = [10, 20]\n",
    "# K_VALS = [2**i for i in range(6, 15)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_dataset(DATASET_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 209527, number of features: 318358\n"
     ]
    }
   ],
   "source": [
    "vec = TfidfVectorizer(stop_words='english')\n",
    "\n",
    "X_bow = vec.fit_transform(X)\n",
    "feature_names = vec.get_feature_names_out()\n",
    "N, D = X_bow.shape\n",
    "print(f'Number of samples: {N}, number of features: {D}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from typing import Callable, List, Any\n",
    "\n",
    "def parallel_map(func: Callable, iterable: List[Any], *args, **kwargs) -> List[Any]:\n",
    "    \"\"\"\n",
    "    Map a function to an iterable in parallel\n",
    "    :param func: Function to map\n",
    "    :param iterable: Iterable to map the function to\n",
    "    :param args: Positional arguments for the function\n",
    "    :param kwargs: Keyword arguments for the function\n",
    "    :return: List of results\n",
    "    \"\"\"    \n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        results = list(executor.map(lambda x: func(x, *args, **kwargs), iterable))\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average number of non-zero features per sample: 29.26\n"
     ]
    }
   ],
   "source": [
    "mfhs = np.array([np.array([MultiFeatureHasher(feature_names=feature_names,\n",
    "                                              n_features=K,\n",
    "                                              n_hashes=n_hashes)\n",
    "                           for n_hashes in range(1, NUM_HASHES + 1)])\n",
    "                 for K in K_VALS])\n",
    "\n",
    "X_dense_bow = dense_X(X_bow, feature_names)\n",
    "print(f'Average number of non-zero features per sample: {np.average([len(x) for x in X_dense_bow]):.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "hashed_Xs = parallel_map_2d(apply_mfh, mfhs, X_dense_bow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGD Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy without dimensionality reduction (318358 features): 0.5080\n"
     ]
    }
   ],
   "source": [
    "baseline_accuracy = train_and_evaluate_model(X_bow, y, model='sgd')\n",
    "print(f\"Accuracy without dimensionality reduction ({D} features): {baseline_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_accuracies = parallel_map_2d(train_and_evaluate_model, hashed_Xs, y, 'sgd')\n",
    "for K, accuracies in zip(K_VALS, sgd_accuracies):\n",
    "    for i, accuracy in enumerate(accuracies):\n",
    "        print(f\"Accuracy with {K} features and {i+1} hash(es): {accuracy:.4f}\")\n",
    "\n",
    "# for K, Xs_k in zip(K_VALS, Xs):\n",
    "#     print(f\"Training with {K} features\")\n",
    "#     accuracies = parallel_map(train_and_evaluate_model, Xs_k, y, 'sgd')\n",
    "#     sgd_accuracies[K_VALS.index(K)] = accuracies\n",
    "#     for i, accuracy in enumerate(accuracies):\n",
    "#         print(f\"Accuracy with {K} features and {i+1} hash(es): {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K: 64\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'multi_feature_hashing' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 16\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mK: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mK\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Feature Hashing\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# hasher = FeatureHasher(n_features=K, input_type='pair')\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# X_hashed = hasher.transform(X_hasher_input)\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     14\u001b[0m \n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Multi-Feature Hashing\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m Xs \u001b[38;5;241m=\u001b[39m \u001b[43mmulti_feature_hashing\u001b[49m(X_hasher_input, K)\n\u001b[0;32m     17\u001b[0m train_test_tuples \u001b[38;5;241m=\u001b[39m [train_test_split(X, y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.3\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m X \u001b[38;5;129;01min\u001b[39;00m Xs]\n\u001b[0;32m     18\u001b[0m accuracies \u001b[38;5;241m=\u001b[39m train_and_evaluate_model_sgd_parallel(train_test_tuples)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'multi_feature_hashing' is not defined"
     ]
    }
   ],
   "source": [
    "Ks = [2**i for i in range(6, 18)] # Number of components s.t. K << D\n",
    "Hs = range(1, 6) # Number of hashes for multi-feature hashing\n",
    "\n",
    "mfh_accuracies = np.zeros((len(Ks), len(Hs)))\n",
    "\n",
    "for K in Ks:\n",
    "    print(f\"K: {K}\")\n",
    "    # Feature Hashing\n",
    "    # hasher = FeatureHasher(n_features=K, input_type='pair')\n",
    "    # X_hashed = hasher.transform(X_hasher_input)\n",
    "    # X_train_hashed, X_test_hashed, y_train, y_test = train_test_split(X_hashed, y, test_size=0.3, random_state=42)\n",
    "    # fh_accuracy = train_and_evaluate_model_sgd(X_train_hashed, X_test_hashed, y_train, y_test)\n",
    "    # fh_accuracies.append(fh_accuracy)\n",
    "    \n",
    "    # Multi-Feature Hashing\n",
    "    Xs = multi_feature_hashing(X_hasher_input, K)\n",
    "    train_test_tuples = [train_test_split(X, y, test_size=0.3, random_state=42) for X in Xs]\n",
    "    accuracies = train_and_evaluate_model_sgd_parallel(train_test_tuples)\n",
    "    for H in Hs:\n",
    "        print(f\"H: {H}, Accuracy: {accuracies[H-1]:.4f}\")\n",
    "\n",
    "    mfh_accuracies[Ks.index(K), :] = accuracies\n",
    "    \n",
    "    \n",
    "    # Cuckoo Feature Hashing\n",
    "    # X_cfh = cuckoo_feature_hashing(X_hasher_input, K, 10)\n",
    "    # X_train_cfh, X_test_cfh, y_train, y_test = train_test_split(X_cfh, y, test_size=0.3, random_state=42)\n",
    "    # cfh_accuracy = train_and_evaluate_model_sgd(X_train_cfh, X_test_cfh, y_train, y_test)\n",
    "    # cfh_accuracies.append(cfh_accuracy)\n",
    "    \n",
    "    \n",
    "    # PCA\n",
    "    # pca = PCA(n_components=K)\n",
    "    # X_pca = pca.fit_transform(X_BoW)\n",
    "    # X_train_pca, X_test_pca, y_train, y_test = train_test_split(X_pca, y, test_size=0.3, random_state=42)\n",
    "    # pca_accuracy = train_and_evaluate_model_sgd(X_train_pca, X_test_pca, y_train, y_test)\n",
    "    # pca_accuracies.append(pca_accuracy)\n",
    "    \n",
    "    # Sparse Random Projection\n",
    "    # srp = SparseRandomProjection(n_components=K)\n",
    "    # X_srp = srp.fit_transform(X_BoW)\n",
    "    # X_train_srp, X_test_srp, y_train, y_test = train_test_split(X_srp, y, test_size=0.3, random_state=42)\n",
    "    # srp_accuracy = train_and_evaluate_model_sgd(X_train_srp, X_test_srp, y_train, y_test)\n",
    "    # srp_accuracies.append(srp_accuracy)\n",
    "    \n",
    "    # Johnson-Lindenstrauss\n",
    "    # jl = GaussianRandomProjection(n_components=K)\n",
    "    # X_jl = jl.fit_transform(X_BoW)\n",
    "    # X_train_jl, X_test_jl, y_train, y_test = train_test_split(X_jl, y, test_size=0.3, random_state=42)\n",
    "    # jl_accuracy = train_and_evaluate_model_sgd(X_train_jl, X_test_jl, y_train, y_test)\n",
    "    # jl_accuracies.append(jl_accuracy)\n",
    "    \n",
    "    # t-SNE\n",
    "    # tsne = TSNE(n_components=K)\n",
    "    # X_tsne = tsne.fit_transform(X_BoW)\n",
    "    # X_train_tsne, X_test_tsne, y_train, y_test = train_test_split(X_tsne, y, test_size=0.3, random_state=42)\n",
    "    # tsne_accuracy = train_and_evaluate_model_sgd(X_train_tsne, X_test_tsne, y_train, y_test)\n",
    "    # tsne_accuracies.append(tsne_accuracy)\n",
    "    \n",
    "    # Autoencoder\n",
    "    # Not implemented\n",
    "    \n",
    "    # print(f\"K: {K}, \"\n",
    "    #         f\"Accuracy (Feature Hashing): {fh_accuracy:.4f}, \"\n",
    "    #         f\"Multi Feature Hashing: {mfh_accuracy:.4f}, \"\n",
    "    #         # f\"Cuckoo Feature Hashing: {cfh_accuracy:.4f}\"\n",
    "    #         # f\"Accuracy (PCA): {pca_accuracy:.4f}, \"\n",
    "    #         # f\"Accuracy (Sparse Random Projection): {srp_accuracy:.4f}, \"\n",
    "    #         # f\"Accuracy (Johnson-Lindenstrauss): {jl_accuracy:.4f}, \"\n",
    "    #         # f\"Accuracy (t-SNE): {tsne_accuracy:.4f}\"\n",
    "    #         )\n",
    "    \n",
    "\n",
    "# Plot accuracies vs K\n",
    "# plt.plot(Ks, fh_accuracies, label='Feature Hashing')\n",
    "# plt.plot(Ks, mfh_accuracies, label='Multi-Feature Hashing')\n",
    "# plt.plot(Ks, cfh_accuracies, label='Cuckoo Feature Hashing')\n",
    "# plt.plot(Ks, pca_accuracies, label='PCA')\n",
    "# plt.plot(Ks, srp_accuracies, label='Sparse Random Projection')\n",
    "# plt.plot(Ks, jl_accuracies, label='Johnson-Lindenstrauss')\n",
    "# plt.plot(Ks, tsne_accuracies, label='t-SNE')\n",
    "# Plot all Hs\n",
    "for H in Hs:\n",
    "    plt.plot(Ks, mfh_accuracies[:, H-1], label=f'Multi-Feature Hashing (H={H})')\n",
    "plt.axhline(y=baseline_accuracy, color='r', linestyle='--', label='Baseline')\n",
    "plt.xlabel('K')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deprecated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_feature_hashing(X_hasher_input, n_features, n_hashes):\n",
    "    X_hashed = np.zeros((len(X_hasher_input), n_features))\n",
    "    \n",
    "    for i, row in enumerate(X_hasher_input):\n",
    "        row_features, row_values = zip(*row)\n",
    "        feature_indices = np.searchsorted(feature_names, row_features)\n",
    "        \n",
    "        hs = hashes[:n_hashes][:, feature_indices] % n_features\n",
    "        v = np.array(row_values) * signs[feature_indices]\n",
    "        \n",
    "        for h in hs:\n",
    "            np.add.at(X_hashed[i], h, v)\n",
    "\n",
    "    return X_hashed\n",
    "\n",
    "def cuckoo_feature_hashing(X_hasher_input, n_features, max_loop):\n",
    "    X_hashed = np.zeros((len(X_hasher_input), n_features))\n",
    "    buckets_1 = {f: (hashes_1[f] % n_features) for f in feature_names}\n",
    "    buckets_2 = {f: (hashes_2[f] % n_features) for f in feature_names}\n",
    "    for i, row in enumerate(X_hasher_input):\n",
    "        for f, v in row.items():\n",
    "            h1, h2, sign = buckets_1[f], buckets_2[f], feature_signs[f]\n",
    "            value = sign * v\n",
    "            assigned = False\n",
    "            for _ in range(max_loop):\n",
    "                if X_hashed[i, h1] == 0:  \n",
    "                    X_hashed[i, h1] = value\n",
    "                    assigned = True\n",
    "                    break  \n",
    "                else:\n",
    "                    # Swap with existing value and move it to the alternative location\n",
    "                    value, X_hashed[i, h1] = X_hashed[i, h1], value\n",
    "                    h1, h2 = h2, (h1 + h2) % n_features  # Rehash to the next location\n",
    "            if not assigned:\n",
    "                X_hashed[i, h1] += value  \n",
    "            \n",
    "    return csr_matrix(X_hashed)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
